{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD2: Parts of Speech tagging for sentimment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging is the process of converting a sentence, in the form of a list of words,\n",
    "into a list of tuples, where each tuple is of the form (word, tag). The tag is a part-of-speech\n",
    "tag, and signifies whether the word is a noun, adjective, verb, and so on.\n",
    "\n",
    "Most of the taggers are trainable. They use a list of tagged sentences as their training data, such as\n",
    "what you get from the tagged_sents() method of a TaggedCorpusReader class. With these training\n",
    "sentences, the tagger generates an internal model that will tell it how to tag a word. Other taggers\n",
    "use external data sources or match word patterns to choose a tag for a word.\n",
    "All taggers in NLTK are in the nltk.tag package. Many taggers can also be combined into a backoff\n",
    "chain, so that if one tagger cannot tag a word, the next tagger is used, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a unigram part-of-speech tagger\n",
    "\n",
    "UnigramTagger can be trained by giving it a list of tagged sentences at initialization.\n",
    "\n",
    ">>> from nltk.tag import UnigramTagger\n",
    "\n",
    ">>> from nltk.corpus import treebank\n",
    "\n",
    ">>> train_sents = treebank.tagged_sents()[:3000]\n",
    "\n",
    ">>> tagger = UnigramTagger(train_sents)\n",
    "\n",
    ">>> treebank.sents()[0]\n",
    "\n",
    "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director','Nov.', '29', '.']\n",
    "\n",
    ">>> tagger.tag(treebank.sents()[0])\n",
    "\n",
    "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will',\n",
    "'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'),('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 3000 tagged sentences of the treebank corpus as the training set to\n",
    "initialize the UnigramTagger class. Then, we see the first sentence as a list of words,\n",
    "and can see how it is transformed by the tag() function into a list of tagged tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\rosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier où vous avez décompressé le dataset\n",
    "dataset_directory = \"C:/Users/rosel/Desktop/ML_NLP/txt_sentoken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sous-répertoires pour critiques positives et négatives\n",
    "pos_dir = os.path.join(dataset_directory, 'pos')\n",
    "neg_dir = os.path.join(dataset_directory, 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(directory, label):\n",
    "    \"\"\"Charge les critiques d'un répertoire donné et attribue une étiquette\"\"\"\n",
    "    reviews = []\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            text = file.read().strip()\n",
    "            reviews.append((text, label))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les critiques positives et négatives\n",
    "positive_reviews = load_reviews(pos_dir, 'positive')\n",
    "negative_reviews = load_reviews(neg_dir, 'negative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les critiques\n",
    "all_reviews = positive_reviews + negative_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mélanger le dataset: pour plus tardl'entrainer et le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Tokenise et étiquette morpho-syntaxique pour chaque critique\n",
    "tagged_reviews = [(word_tokenize(review), label) for review, label in all_reviews]\n",
    "tagged_reviews = [(nltk.pos_tag(tokens), label) for tokens, label in tagged_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adverbs(tagged_tokens):\n",
    "    \"\"\"Extrait les adverbes d'une liste de tokens étiquetés.\"\"\"\n",
    "    return [word for word, pos in tagged_tokens if pos.startswith('RB')]\n",
    "\n",
    "# Extraire les adverbes pour chaque critique\n",
    "adverbs_in_reviews = [(extract_adverbs(tagged_tokens), label) for tagged_tokens, label in tagged_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adverbs_in_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "def get_sentiment(adverb):\n",
    "    \"\"\"Obtient le score de sentiment pour un adverbe à l'aide de SentiWordNet.\"\"\"\n",
    "    synsets = list(swn.senti_synsets(adverb, 'r'))  # 'r' pour adverbes\n",
    "    if not synsets:\n",
    "        return 0  # Aucun score si l'adverbe n'est pas trouvé dans SentiWordNet\n",
    "    \n",
    "    # Utiliser le premier synset par défaut (pourrait être amélioré en utilisant des méthodes de désambiguïsation)\n",
    "    return synsets[0].pos_score() - synsets[0].neg_score()\n",
    "\n",
    "# Calculer le score de sentiment pour chaque adverbe dans les critiques\n",
    "sentiments_in_reviews = [(sum(get_sentiment(adverb) for adverb in adverbs), label) for adverbs, label in adverbs_in_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiments_in_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de la classification: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#Classer les critiques en fonction des scores de sentiment\n",
    "def classify_review(sum_score):\n",
    "    return \"pos\" if sum_score > 0 else \"neg\"\n",
    "\n",
    "predicted_labels = [classify_review(score) for score, _ in sentiments_in_reviews]\n",
    "\n",
    "# Calculer la précision de la classification\n",
    "actual_labels = [label for _, label in sentiments_in_reviews]\n",
    "correctly_classified = sum(1 for predicted, actual in zip(predicted_labels, actual_labels) if predicted == actual)\n",
    "\n",
    "accuracy = correctly_classified / len(predicted_labels)\n",
    "\n",
    "print(f\"Précision de la classification: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sum_ for sum_, _ in sentiments_in_reviews]\n",
    "y = [label for _, label in sentiments_in_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Reshape les données car nous avons une seule caractéristique\n",
    "X_train = [[x] for x in X_train]\n",
    "X_test = [[x] for x in X_test]\n",
    "\n",
    "# Entraîner le modèle\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.18      0.26       209\n",
      "    positive       0.47      0.79      0.59       191\n",
      "\n",
      "    accuracy                           0.47       400\n",
      "   macro avg       0.47      0.48      0.42       400\n",
      "weighted avg       0.47      0.47      0.42       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre modèle a une précision de 47%, ce qui n'est pas idéal, essayons de l'améliorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "\n",
    "Au lieu de se concentrer uniquement sur le score de sentiment, nous pouvons transformer les critiques en vecteurs numériques à l'aide de TF-IDF. Cette technique prend en compte l'importance d'un mot dans un document par rapport à l'ensemble du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('robert redford\\'s a river runs through it is not a film i watch often . \\nit is a masterpiece -- one of the better films of recent years . \\nuntil 1994 , it was my second favorite film of all time . \\nthe acting and direction is top-notch -- never sappy , always touching . \\na friend of mine once reported that he avoided it because \" i was afraid it would just be really politically correct , and tick me off . \" \\nall i could do was tell him to go in unbiased , and enjoy . \\nit is one of the few movies that has completely reduced me to tears . \\nbut certain memories should not often be rereleased -- in the last few shots , you have to cry . \\nupon my first viewing i left bawling . \\nit is not flawless -- but it is so very good , that you can\\'t help but be effected . \\nthe opening is dangerously nolstalgic and sentimental -- watching these shots of people who have been dead so long , gives you a feeling of perspective and history observation that you will find in very few other films . \\nmartin scorsese once described the movies as a dream state -- like taking dope , and immersing yourself in an alternative world . \\nthat is what a river runs through it does . \\nit exploits the unique power of cinema to engross you and help to forget your real self . \\nboth times i\\'ve seen it , its been hard ( again to quote scorsese ) waking up . \\nbut the dream is lovely .', 'positive'), ('in my review of \" the spy who shagged me , \" i postulated an unbreakable law of film physics : every time a sequel is as good as or better than the previous film in the series , it is followed by a third movie that is a bore . \\nthe cause is probably complacency ; a studio sighs with relief when part 2 lives up to expectations and figures part 3 is a sure thing . \\n \" scream 3 \" provides the latest proof of this rule . \\nin los angeles production has begun on \" stab 3 : return to woodsboro , \" the most recent installment in the series of movies inspired by the murders surrounding sidney prescott ( neve campbell ) . \\nhowever , life soon starts imitating art , and \" stab \" cast members turn up stabbed . \\nsmelling yet another book deal , gale weathers ( courteney cox arquette ) comes to the set to investigate and finds her ex-boyfriend dewey riley ( david arquette ) acting as a technical consultant and getting chummy with jennifer ( parker posey ) , the actress playing gale in \" stab 3 . \" elsewhere , our heroine sidney is living in hiding under an assumed name . \\n . \\n . \\nuntil she gets a phone call from a familiar evil voice . \\nthe late randy meeks ( jamie kennedy ) makes a surprise guest appearance via video to explain the rules of a trilogy . \\nhe notes the third chapter in a trilogy has an overabundance of exposition and a huge backstory to contend with . \\nindeed , \" scream 3 \" tries to link its murders back to the one that started it all , the murder of sidney\\'s mother maureen before the beginning of the original \" scream . \" \\nat the scene of each murder in \" scream 3 , \" the killer leaves a photo of sidney\\'s mother maureen as a teenager in hollywood and even includes a note claiming to be her real killer . \\nto find out who the killer is , our intrepid investigators have to uncover what happened during maureen\\'s missing years when she was a starlet appearing in low-budget horror films . \\n ( even with that little information , you can probably already guess what the killer\\'s relationship to sidney is ) . \\nunlike its predecessors , \" scream 3 \" doesn\\'t have the guts to even suggest that the central characters might be the killer . \\nthe characters we do suspect are all undeveloped , so that by the end we don\\'t even care who the killer is . \\nthe jaded detective ( patrick dempsey ) ? \\nthe kinky producer ( lance henriksen ) ? \\nthe driven young director ( scott foley ) ? \\nthe ingenue ( emily mortimer ) ? \\nthe character who turns out to be the killer seems to be selected at random . \\nwes craven supposedly filmed three different endings to keep the real one a secret , so it\\'s quite possible the one in the final cut was randomly chosen . \\nthe series\\' trademark references to other horror films have become trite and obvious . \\npossibly it\\'s the absence of screenwriter kevin williamson , who penned the first two , or maybe it\\'s that the hip ironic stance eventually consumes itself and a series that parodies film cliches eventually becomes a cliche . \\ni groaned as an attack on sidney from the first \" scream \" was repeated moment-for-moment in the hollywood set of her home . \\nat some point , referencing becomes just a means to cover up a poverty of new ideas . \\n \" scream 3 \" also continues the tradition of having an eclectic set of cameos and familiar faces in small roles . \\nlook for jenny mccarthy , carrie fisher , patrick warburton ( puddy from \" seinfeld \" ) , roger corman , and jason mewes and kevin smith ( as jay and silent bob ) to walk through at some point . \\nall these bit players put forth more effort than the series\\' returning stars , who are probably saving their energy for the long post- \" scream \" job search . \\nanother prediction i made in a previous review has come to pass : more movies are copying \" the blair witch project \" \\'s web strategy . \\n \" scream 3 \" has three official websites that ( wink , wink ) pretend that the events of the movie are real and provide additional backstory information not covered in the movie . \\nthe sunrise studios site ( scream3 . com ) has trailers for other sunrise releases as well as the \" latest \\'stab 3\\' news . \" \\nthere\\'s also a gail weathers official site ( galeweathers . com ) and a sunrise sucks site that has more \" stab \" scandals the studio wants to cover up ( sunrisesucks . com ) . \\ncraven and company promise that this is the last installment in the \" scream \" series . \\nwhile i hope that\\'s true , i don\\'t hold out much hope-horror movie series are even harder to kill than their monsters . \\nthere\\'s a \" halloween h2k \" in the works , even though michael myers was beheaded in \" h20 , \" and a \" freddy vs . jason \" has been talked about for awhile , despite the fact that both characters were \" killed off . \" \\nthere\\'s bound to be a \" scream 4 \" someday , even if it starts over with a new set of movie-star wannabes . \\nbottom line : they should have called this one \" yawn . \"', 'negative'), (\"who knew that in 16 years eddie murphy , who made such a brash , raucous big-screen splash in _48_hrs . _ , \\nwould become . . . \\ncuddly . \\nthe disconcerting trend begun in this summer's cutesy , largely laugh-free _doctor_dolittle_ continues with this earnest-to-a-fault dramedy . \\nalthough he is top-billed , here murphy is merely support for jeff goldblum , who plays ricky hayman , the programming director at a home shopping network . \\nsales are way down , and ricky's job hangs by a thread until he meets g ( murphy ) , a mysterious spiritual guru whom a desperate ricky puts on the air . \\nwhile sales skyrocket and g becomes an overnight sensation , the reinvigorated ricky's greed grows , endangering his budding romance with a goodhearted media research consultant ( kelly preston ) . \\nwriter tom schulman has some promising ideas , satirizing home shopping and infomercials and the nature of instant celebrity . \\nbut these ideas would have more bite if stephen herek had invested any energy into the direction of the film . \\nthe sluggishly paced _holy_man_ is not only slow and overlong ( 113 minutes ) , but an unfunny bore , and murphy can do little to juice up the proceedings ; cleansed of both the attitude _and_ comic sensibility that made him a star ( g is , for the most part , a straight man ) , he is a curiously lifeless presence . \\ngoldblum is actually quite good , but it's hard for the audience to sustain much interest in his character and spiritual journey when the director doesn't seem to be much interested , either .\", 'negative'), ('linda fiorentino disappeared off the radar after a deservedly heralded turn in the cable pic the last seduction , and her being cast as dogma\\'s lead is nothing short of inexplicable . \\nshe\\'s still in fine form as bethany , an abortion clinic worker who\\'s lost her faith . \\none night , a visitor from heaven makes a fiery entrance in bethany\\'s bedroom . \\nhe is metatron ( alan rickman ) , the voice of god , and he needs her help : she must stop two fallen angels from entering a new jersey church-the fate of the universe depends on it . \\ngod would do it him/herself , but he/she is . . . missing , having taken up human form somewhere on earth never to be heard from again . \\nbethany is joined on her road trip to the garden state by the \" prophets \" jay ( jason mewes ) and silent bob ( kevin smith , doing double-duty ) , the slacker minstrels who have appeared in all of smith\\'s films thus far . \\nat some point , rock drops naked out of the sky as rufus , the undocumented ( and very black ) \" thirteenth apostle \" , and offers his assistance , as does divine stripper serendipity ( salma hayek ) . \\nit\\'s a wild ride . \\nthey\\'re in pursuit of loki and bartleby ( damon and affleck , respectively-this is probably the sharpest either has ever been ) , who were banished from heaven to wisconsin and have discovered a dogmatic loophole that will enable their return . \\nloki decides to wreak havoc along the way with the knowledge that his sins will be absolved at the pearly gates . \\nat one point , he terrorizes a boardroom full of suits with an angry combination of words and bullets . \\nit\\'s a nasty , guiltily enjoyable little scene that asks , \" how corrupt are you ? \" . \\nwings of desire this ain\\'t . \\nsince debuting with clerks , smith has grown as a director , particularly in terms of working with actors . \\n ( chris rock is this film\\'s only weak link-between jokes , he\\'s wooden . ) \\nhis no-frills visual style hasn\\'t changed much over the years , though ( dogma\\'s widescreen compositions at least have blockbuster affectations ) , nor has his writing-his characters still sit around delivering one caustic , hilarious speech after another . \\ndogma chips away at big religious issues-namely , the hypocrisy that accompanies any organized system of beliefs-eloquently and articulately , but a few of the monologues sound too much like blatant exposition . \\nas well , the verbal introduction of each new person seems to take forever . \\nany movie with this much weighty talk would have a hard time maintaining momentum ( hurlyburly , anyone ? ) , and eventually dogma\\'s pacing goes slack . \\na long diatribe from bartleby late in the game , in which he laments the destiny of celestial beings , comes at a point when we\\'ve heard enough . \\nbecause his change of heart ( bartleby is initially the good cop to loki\\'s bad ) drives the climax , said rant is given a great deal of screen time . \\nsure , affleck deserved a big moment ( damon steals their scenes together prior ) , but it ultimately makes the film and us feel bloated . \\nlike tarantino , smith was a video-age sponge who became a sample-mad indie filmmaker . \\ndogma pays welcome homage to an eclectic batch of movies , including indiana jones and the last crusade , with silent bob doing his best harrison ford , and weird science-a shit demon attacks our heroes ! \\nsmith also has a kitchen sink brand of humour : his dexterous maneuvering between the satirical ( a cardinal played by george carlin attempts to mount a publicity campaign with the slogan \" catholicism wow ! \" ) and the scatalogical ensures that no lover of comedy will leave dogma feeling malnourished . \\ni bust ( ed ? ) a gut on several occasions . \\nproceedings also get off on the right foot with the opening with the funniest disclaimer ever . \\nit\\'s a disclaimer unlikely to put protestors at ease , for to read it , one actually has to see dogma . \\nthe prerelease ballyhoo is in the tradition of the last temptation of christ\\'s , martin scorsese\\'s 1988 adaptation of nikos kazantzakis\\' controversial novel , in that it is not directly linked to the picture\\'s content but to rumours and heresy . \\nthere\\'s a famous anecdote about fletch director michael ritchie inviting picketers of the last temptation of christ into a screening on his dime , just so they could know for certain what they were rallying against . \\n ( not one of them had watched it . ) \\nevery single person refused . \\nsmith and scorsese have a lot in common , and so do the two films in question , because both smith\\'s bethany and scorsese\\'s jesus are hollow shells without their faith . \\nin fact , dogma\\'s denouement ( which follows a thrilling showdown that\\'s worth the wait ) is a catholic love-in , a veritable recruitment poster . \\n ( i felt sentimental about a religion i don\\'t belong to . \\nnow that\\'s powerful filmmaking . ) smith is nothing if not sincere about his own devotion to god , and that spirituality shines through . \\nit\\'s enough to make me forgive dogma for its editorial sins . \\nmy religion is movies . \\nwhen the catholic league beats on dogma for imaginary crimes against a doctrine , in a roundabout way they\\'re attacking what i live for : freedom of expression through celluloid . \\ni therefore feel that , although i\\'m no bible-thumper , i\\'m at least as qualified to criticize dogma as william donohue and his followers .', 'positive'), (\"notice : this is a review and analysis of exotica . \\nthe first part of this piece is the review , the second part contains some analysis of the movie which might be construed as spoilers . \\nif you have not seen the movie and after reading the first part you intend to do so , then save the second part for the discussion afterwards . \\nstarring : bruce greenwood , mia kirshner , elias kosteas , don mckellar , arsinee khanijian , sarah polley director : atom egoyan screenplay : atom egoyan \\nexotica is a film that grows on retrospection . \\nexotica keeps the viewer guessing about the relationship between the various characters in the film . \\nall of the people know each other , but apart from that , there seems to be no other reason why to select such set and follow them in this fictional account . \\nthe director hints for possible solutions , using a multi-line plot , so popular with critics in mystery train , and used to good advantage by quentin tarantino in pulp fiction . \\nexotica reaches a whole new dimension using this technique . \\nat the end it is surprising to see how well the pieces of the puzzle fit together , in spite their apparent unconnectedness and even misleading features . \\nthe out-of-chronological-order technique has become ever so popular , perhaps even de rigueur , for biographical films . \\nsimilarly , we can now expect to see more movies in the future which will use , to varying extent , converging multiplots . \\non a first glance , once the multi-plot puzzle in exotica is solved , there seems to be little left to look at . \\nbut perceptive minds which take the time to dig further will be rewarded with interesting views on life or rather , commentaries on views of life . \\nexotica is very much worth seeing . \\nit opened to critic's praise worldwide ( i first saw it in mexico city , last december ) . \\nin canada , it broke records for a movie of its kind , which prompted the american distributor to go for a wide release . \\napart from a strong plot , acting is very convincing , and the soundtrack seems as if made for the movie . \\nthe spoon-fed-entertainment crowd may not appreciate this movie , and thus it might last little on screen . \\nbut if you want to try a movie a cut above the crowd , with an originality that is ever so rare , by all means see exotica . \\nanalysis ( * * spoilers * * ahead ) \\nwhat is behind the complex plot in exotica ? \\nfirst , a common theme of the quest for gratification by monetary means . \\nthe lone tax-auditor , the repressed homosexual pet shop owner , the pregnant woman which runs the nightclub , the rich man which has the club remodeled , the audience at the movie theatre , all use personal wealth to buy palliative relief for the penuries of the soul . . . . \\nthen we have the quest for gratification through visual means by most of the same people , including those who sit watching exotica . . . . \\nin that regard exotica stands for onlookers at a nightclub , for the rich man looking through silver mirrors , and poor-rich people looking at other's people lives through a silver screen . \\nexotica also stands for unwanted society attention into the lives of other people , such as the tax auditor and the pet shop owner . \\nexotica is the customer agent looking at the pet shop owner , which in turn is looking at the core of the problems between the strip dancer and the tax auditor through the detached eye of a gay person ( no attraction to the strip dancer ) , and only interested on avoiding jail ( no personal relationship with the tax auditor ) . \\nin exotica everybody is watching , and what is worse , everybody knows . \\nsecond , exotica is about isolated people holding back their feelings ; about people which by voluntary or involuntary means transfer their view of reality to other characters . \\nthe strip dancer becomes the proverbial daughter , the dj becomes the proverbial killer by means of breaking the relationship between the father and the proverbial daughter . \\nthe niece becomes the baby sitter , the baby sitter becomes the dancer , and the dancer becomes the proverbial daughter . \\nthe pet shop owner becomes the proverbial dj , by finding the proverbial daughter . \\na chain made of real and imagined links coming around full circle , just as everything comes around to a fitting whole at the end of the movie .\", 'positive')]\n"
     ]
    }
   ],
   "source": [
    "print(all_reviews[:5])  # Affichez les 5 premières entrées pour vérifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'accord, il semble que all_reviews soit une liste de tuples, où chaque tuple contient une seule chaîne de caractères (la critique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = [review[0] for review in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela transformera all_reviews en une simple liste de chaînes de caractères. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Créez un vecteur TF-IDF basé sur les critiques\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(all_reviews)\n",
    "\n",
    "# Divisez à nouveau les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.84      0.83       209\n",
      "    positive       0.82      0.79      0.80       191\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.82      0.81      0.81       400\n",
      "weighted avg       0.82      0.81      0.81       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/Users/rosel/Desktop/ML_NLP/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enregistrez le modèle formé et le vectorizer pour une utilisation ultérieure\n",
    "joblib.dump(classifier, 'c:/Users/rosel/Desktop/ML_NLP/sentiment_model.pkl')\n",
    "joblib.dump(vectorizer, 'c:/Users/rosel/Desktop/ML_NLP/tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné\n",
    "model = joblib.load('c:/Users/rosel/Desktop/ML_NLP/sentiment_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 18:47:50.371 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\rosel\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title('Analyseur de sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Convertir le texte en minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenisation\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Suppression des mots vides\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une boîte de texte pour l'entrée utilisateur\n",
    "user_input = st.text_area(\"Entrez votre texte ici\")\n",
    "\n",
    "if st.button('Analyser'):\n",
    "    processed_text = preprocess(user_input)\n",
    "    \n",
    "    # Transformez le texte prétraité avec le vecteur TF-IDF\n",
    "    X_user_input = vectorizer.transform([processed_text]) \n",
    "    \n",
    "    # Prédire le sentiment\n",
    "    prediction = model.predict([processed_text])\n",
    "    \n",
    "    # Afficher le résultat\n",
    "    if prediction[0] == 1:  # Supposons que 1 soit pour \"positif\"\n",
    "        st.write(\"Le texte semble avoir un sentiment positif.\")\n",
    "    else:  # Supposons que 0 soit pour \"négatif\"\n",
    "        st.write(\"Le texte semble avoir un sentiment négatif.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
